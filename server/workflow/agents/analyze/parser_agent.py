# server/workflow/agents/analyze/parser_agent.py

"""
íŒŒì„œ ì—ì´ì „íŠ¸
"""

import os
import subprocess
from datetime import datetime
from server.workflow.agents.base.base_utility_agent import BaseUtilityAgent, AgentState
from server.db.dao.entry_point_list_dao import insert_entry_points_bulk, delete_entry_points_by_project_and_date
from server.db.schema import EntryPointCreate
from server.db.database import run_with_db_session
from server.utils.constants import AgentType, AgentResultGroupKey, IndexInputType, DirInfo
from server.utils.file_utils import load_json
from server.utils.config import settings

class ParserAgent(BaseUtilityAgent):
    def __init__(self, session_id: str = None, project_id: str = None):
        super().__init__(role=AgentType.PARSER, session_id=session_id, project_id=project_id)
        
    def _run_internal(self, state: AgentState) -> AgentState:
        agent_state = state["autodiagenti_state"]
        project_id = agent_state.get("project_id", "")
        project_name = agent_state.get("project_name", "")
        project_path = agent_state.get("project_path", "")
        analyzed_date = agent_state.get("analyzed_date", datetime.now().strftime("%Y%m%d"))
        analyzed_at = agent_state.get("analyzed_at", datetime.now())
        self.logger.info(f"ğŸ“¢ session_id: [{self.session_id}],  project_id: [{project_id}]")
        
        file_info = agent_state.get("file_info", {})
        self.logger.info(f"ğŸ“¢ğŸ“¢ file_info: [{file_info}]")
        file_full_path = os.path.join(file_info.get("file_path", ""), file_info.get("file_name", ""))

        # ë¶„ì„ ì„¤ì •        
        filter_options = agent_state.get("filter_options", {})
        include_method_text = filter_options.get("include_method_text", True)
        custom_annotations = filter_options.get("custom_annotations", None)
        exclude_packages = filter_options.get("exclude_packages", None)
        
        output_dir = os.path.join(DirInfo.PARSER_OUTPUT_DIR, project_id)
        
        # Parser í˜¸ì¶œ
        result: bool = self._run_parser_jar(source_dir=project_path, output_dir=output_dir, include_method_text=include_method_text, exclude_packages=exclude_packages, custom_annotations=custom_annotations)
        
        # Entry Point ì €ì¥
        if result:
            self._save_entry_point_to_db(project_id=project_id, project_name=project_name, session_id=self.session_id, analyzed_date=analyzed_date, analyzed_at=analyzed_at, file_path=file_full_path)
        
        parser_result = {
            "input_type": IndexInputType.PARSER,
            "output_dir": os.path.join(DirInfo.PARSER_OUTPUT_DIR, project_id, project_name),
            "success": result
        }
        
        result = {
            AgentResultGroupKey.PARSER_RESULT: parser_result,
            AgentResultGroupKey.CURRENT_SOURCE_DATA: parser_result
        }
        
        return self.wrap_multiple_sources(result)
    
    def _run_parser_jar(self,
        source_dir: str,
        output_dir: str,
        include_method_text: bool = True,
        exclude_packages: str = "", # ""java.,jakarta.,org.springframework.",
        custom_annotations: str = '',
        timeout: int = 60
    ) -> bool:
        """
        JavaParser ë¶„ì„ê¸°ë¥¼ subprocessë¡œ ì‹¤í–‰í•˜ì—¬ call tree ë° ë©”ì„œë“œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.

        Args:
            source_dir (str): ë¶„ì„ ëŒ€ìƒ Java ì†ŒìŠ¤ ë£¨íŠ¸ ê²½ë¡œ
            include_method_text (bool): ë©”ì„œë“œ ë³¸ë¬¸ í¬í•¨ ì—¬ë¶€
            exclude_packages (str): ì œì™¸í•  íŒ¨í‚¤ì§€ ì ‘ë‘ì–´ (ì‰¼í‘œ êµ¬ë¶„)
            custom_annotations (str): ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ êµ¬ë¶„ìš© ì‚¬ìš©ì ì •ì˜ ì–´ë…¸í…Œì´ì…˜ (ì‰¼í‘œ êµ¬ë¶„)
            timeout (int): í”„ë¡œì„¸ìŠ¤ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€ (True: ì„±ê³µ, False: ì‹¤íŒ¨)
        """
        jar_path:str = settings.JAVA_PARSER_JAR_PATH
        output_dir:str = output_dir
        
        if not os.path.isfile(jar_path):
            self.logger.error(f"âŒ JAR íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {jar_path}")
            return False

        if not os.path.isdir(source_dir):
            self.logger.error(f"âŒ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_dir}")
            return False

        os.makedirs(output_dir, exist_ok=True)

        command = [
            "java", 
            "-Dfile.encoding=UTF-8",
            "-jar", 
            jar_path,
            f"--source-dir={source_dir}",
            f"--output-dir={output_dir}",
            f"--include-method-text={str(include_method_text).lower()}"
        ]

        if exclude_packages:
            command.append(f"--exclude-packages={exclude_packages}")
        if custom_annotations:
            command.append(f"--custom-annotations={custom_annotations}")
            
        self.logger.info(f"ğŸ“¢ğŸ“¢ğŸ“¢ command: [{command}]")

        try:
            env = os.environ.copy()
            env["LANG"] = "ko_KR.UTF-8"
            env["LC_ALL"] = "ko_KR.UTF-8"

            self.logger.info(f"ğŸš€ JavaParser ì‹¤í–‰ ì¤‘... \n{' '.join(command)}")
            self._run_with_live_log(command, timeout=timeout, env=env)
            self.logger.info("âœ… JavaParser ì‹¤í–‰ ì™„ë£Œ")
            return True
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ JavaParser ì‹¤í–‰ ì‹¤íŒ¨ (exit code {e.returncode}): {e}")
        except subprocess.TimeoutExpired:
            self.logger.error("â° JavaParser ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
        except Exception as e:
            self.logger.exception(f"âš ï¸ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return False
    
    def _run_with_live_log(self, command, timeout=None, env=None):
        proc = None
        
        try:
            proc = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding="utf-8",
                bufsize=1,
                env=env
            )

            for line in proc.stdout:
                print(line, end="")   # ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥

            proc.wait(timeout=timeout)

            if proc.returncode != 0:
                raise subprocess.CalledProcessError(proc.returncode, command)

        except subprocess.TimeoutExpired:
            proc.kill()
            self.logger.error(f"\n[ERROR] Timeout after {timeout} seconds")
            raise
        
    def _save_entry_point_to_db(self, project_id: str, project_name: str, session_id: str, analyzed_date: str, analyzed_at: str, file_path: str):
        try:
            # Entry Point íŒŒì¼ ë¡œë“œ
            output_dir = os.path.join(DirInfo.PARSER_OUTPUT_DIR, project_id, project_name)
            entry_point_info_path = os.path.join(output_dir, settings.ENTRY_POINT_INFO_FILE_NAME)
            entry_point_info_list = load_json(entry_point_info_path)
        
            data = []
            for entry_point_info in entry_point_info_list:
                method_fqn = entry_point_info.get("method_fqn")
                
                if method_fqn:
                    entry_point = EntryPointCreate(
                        analyzed_date=analyzed_date,
                        project_id=project_id,
                        entry_point=method_fqn,
                        session_id=session_id,
                        api_name=entry_point_info.get("api_name"),
                        api_method=entry_point_info.get("api_method"),
                        annotation=entry_point_info.get("annotation"),
                        file_path=file_path,
                        analyzed_at=analyzed_at
                    )
                    data.append(entry_point)
            
            self.logger.info(f"ğŸ–¥ï¸ data: {len(data)}")
            
            if data:
                del_count = run_with_db_session(delete_entry_points_by_project_and_date, project_id=project_id, analyzed_date=analyzed_date)
                self.logger.info(f"ğŸ“¢ Entry Point ì‚­ì œ ê±´ìˆ˜: [{del_count}], project_id: {project_id}, analyzed_date: {analyzed_date}")
                result = run_with_db_session(insert_entry_points_bulk, data)
                self.logger.info(f"ğŸ“¢ Entry Point ë“±ë¡ ì™„ë£Œ. project_id:{project_id}, analyzed_date: {analyzed_date}, result:{result}")
            else:
                self.logger.info(f"ğŸ“¢ Entry Point ë“±ë¡ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìŒ. project_id:{project_id}")
        except Exception as err:
            self.logger.error(f"âŒ Entry Point ë“±ë¡ ì˜¤ë¥˜ err:{err}, cause: {err.__cause__}")
    
